import React, {JSX, useEffect, useRef, useState} from 'react';
import {
  StyleSheet,
  Text,
  Button,
  View,
  useWindowDimensions,
  Platform,
  Alert,
  TouchableOpacity,
} from 'react-native';
import {
  CameraPosition,
  DrawableFrame,
  Frame,
  PhotoFile,
  Camera as VisionCamera,
  useCameraDevice,
  useCameraPermission,
} from 'react-native-vision-camera';
import {useIsFocused} from '@react-navigation/core';
import {useAppState} from '@react-native-community/hooks';
import {SafeAreaProvider, SafeAreaView} from 'react-native-safe-area-context';
import {NavigationContainer} from '@react-navigation/native';
import {
  Camera,
  Face,
  FaceDetectionOptions,
  Contours,
  Landmarks,
  useFaceDetector,
} from 'react-native-vision-camera-face-detector';
import {ClipOp, Skia, TileMode} from '@shopify/react-native-skia';
import Animated, {
  useAnimatedStyle,
  useSharedValue,
  withTiming,
} from 'react-native-reanimated';
import {api} from '@/api/request';
import {useProject} from '@/stores/userProject';
import LoadingOverlay from '../LoadingOverlay';
// å±å¹•ä¸­é—´è™šçº¿æ¡†çš„å°ºå¯¸
const BOX_WIDTH = 250;
const BOX_HEIGHT = 350;
export function FaceRecognitionPunch(): JSX.Element {
  const processingRef = useRef(true);
  const stopFrameProcessing = () => {
    processingRef.current = false;
  };
  const startFrameProcessing = () => {
    processingRef.current = true;
  };
  const [title, setTitle] = useState<string>('æŸ¥æ‰¾ä¸­...');
  const [activityLoading, setActivityLoading] = useState<boolean>(false);
  const {myProject} = useProject();
  const {width, height} = useWindowDimensions();
  const {hasPermission, requestPermission} = useCameraPermission();
  const [cameraMounted, setCameraMounted] = useState<boolean>(false);
  const [cameraPaused, setCameraPaused] = useState<boolean>(false);
  const [autoMode, setAutoMode] = useState<boolean>(true);
  const [cameraFacing, setCameraFacing] = useState<CameraPosition>('back');
  const cameraDevice = useCameraDevice(cameraFacing);
  // const faceDetectionOptions = useRef<FaceDetectionOptions>({
  // performanceMode: 'fast',     // æ€§èƒ½æ¨¡å¼ï¼š'fast'ï¼ˆå¿«ï¼Œç‰ºç‰²ç²¾åº¦ï¼‰ or 'accurate'ï¼ˆæ…¢ï¼Œä½†æ›´å‡†ï¼‰
  // classificationMode: 'all',   // åˆ†ç±»æ¨¡å¼ï¼šæ˜¯å¦æ£€æµ‹è¡¨æƒ…ç›¸å…³å±æ€§ï¼ˆççœ¼ã€å¾®ç¬‘ã€å¤´éƒ¨å§¿æ€ï¼‰
  // contourMode: 'all',          // è½®å»“æ¨¡å¼ï¼šæ˜¯å¦è¿”å›äººè„¸è½®å»“ç‚¹ï¼ˆäº”å®˜ã€å¤–è½®å»“çš„å…³é”®ç‚¹ï¼‰
  // landmarkMode: 'all',         // ç‰¹å¾ç‚¹æ¨¡å¼ï¼šæ˜¯å¦æ£€æµ‹å…³é”®ç‚¹ï¼ˆçœ¼ç›ã€é¼»å­ã€å˜´å·´ç­‰ï¼‰
  // windowWidth: width,          // æ£€æµ‹çª—å£å®½åº¦ï¼ˆé€šå¸¸æ˜¯ç›¸æœºé¢„è§ˆåŒºåŸŸï¼‰
  // windowHeight: height,        // æ£€æµ‹çª—å£é«˜åº¦
  // }).current;
  // æ‰‹æŒ æµ‹è¯• å‚æ•°
  let contourSupport: 'all' | 'none' = 'all';
  useEffect(() => {
    if (cameraDevice) {
      console.log('å½“å‰ç›¸æœºè®¾å¤‡ä¿¡æ¯:', cameraDevice);
      if (cameraDevice.position === 'back') {
        contourSupport = 'none';
      } else {
        contourSupport = 'all';
      }
    }
  }, [cameraDevice]);
  const faceDetectionOptions = useRef<FaceDetectionOptions>({
    performanceMode: 'fast',
    classificationMode: 'all',
    landmarkMode: 'all',
    contourMode: contourSupport, // æ‰‹æŒåç½®ä¸æ”¯æŒ
    windowWidth: width,
    windowHeight: height,
  }).current;
  const {stopListeners} = useFaceDetector(faceDetectionOptions);
  const isFocused = useIsFocused();
  const appState = useAppState();
  const [showText, setShowText] = useState('');

  const [isActive, setIsActive] = useState(true);
  const isCameraActive = !cameraPaused && isFocused && appState === 'active';

  //
  // vision camera ref
  //
  const camera = useRef<VisionCamera>(null);
  //
  // face rectangle position
  //
  const aFaceW = useSharedValue(0);
  const aFaceH = useSharedValue(0);
  const aFaceX = useSharedValue(0);
  const aFaceY = useSharedValue(0);
  const aRot = useSharedValue(0);
  const boundingBoxStyle = useAnimatedStyle(() => ({
    position: 'absolute',
    borderWidth: 4,
    borderLeftColor: 'rgb(0,255,0)',
    borderRightColor: 'rgb(0,255,0)',
    borderBottomColor: 'rgb(0,255,0)',
    borderTopColor: 'rgb(0,255,0)',
    // borderTopColor: 'rgb(255,0,0)',
    width: withTiming(aFaceW.value, {
      duration: 100,
    }),
    height: withTiming(aFaceH.value, {
      duration: 100,
    }),
    left: withTiming(aFaceX.value, {
      duration: 100,
    }),
    top: withTiming(aFaceY.value, {
      duration: 100,
    }),
    transform: [
      {
        rotate: `${aRot.value}deg`,
      },
    ],
  }));

  useEffect(() => {
    if (hasPermission) return;
    requestPermission();
  }, []);

  function handleUiRotation(rotation: number) {
    aRot.value = rotation;
  }

  function handleCameraMountError(error: any) {
    console.error('camera mount error', error);
  }

  function handleFacesDetected(faces: Face[], frame: Frame): void {
    console.log(faces);
    if (!processingRef.current) return; // åœæ­¢å¤„ç†

    if (faces.length <= 0) {
      aFaceW.value = 0;
      aFaceH.value = 0;
      aFaceX.value = 0;
      aFaceY.value = 0;
      setShowText('æœªè¯†åˆ«åˆ°äººè„¸');
      return;
    }
    if (faces.length > 1) {
      setShowText('åªèƒ½ä¸€ä¸ªäººè„¸');
      return;
    }

    const face = faces[0];

    const {bounds} = faces[0];
    const {width, height, x, y} = bounds;
    aFaceW.value = width;
    aFaceH.value = height;
    aFaceX.value = x;
    aFaceY.value = y;

    if (
      aFaceX.value >= boxLeft &&
      aFaceX.value + aFaceW.value <= boxRight &&
      aFaceY.value >= boxTop &&
      aFaceY.value + aFaceH.value <= boxBottom
    ) {
      // ğŸ‘ï¸ çœ¼ç›é—­åˆæ£€æµ‹
      if (
        face.leftEyeOpenProbability < 0.8 &&
        face.rightEyeOpenProbability < 0.8
      ) {
        setShowText('è¯·ççœ¼');
        return;
      }

      // ğŸ¯ æ­£é¢æœå‘æ£€æµ‹
      // pitchAngle = ç‚¹å¤´ä¸Šä¸‹è§’åº¦
      // rollAngle = å¤´éƒ¨å€¾æ–œè§’åº¦ï¼ˆæ­ªå¤´ï¼‰
      // yawAngle = å·¦å³è½¬å¤´è§’åº¦
      if (
        !(
          Math.abs(face.pitchAngle) < 6 &&
          Math.abs(face.rollAngle) < 6 &&
          Math.abs(face.yawAngle) < 6
        )
      ) {
        setShowText('è¯·æ­£é¢æœå‘å±å¹•');
        return;
      }

      // âœ… æ‰€æœ‰æ£€æµ‹é€šè¿‡ -> æ‹ç…§
      setShowText('æ£€æµ‹åˆ°äººè„¸ï¼Œå‡†å¤‡æ‹ç…§');
      takePicture();
      stopFrameProcessing(); // ğŸ‘‰ æ‹ç…§åç«‹åˆ»åœæ­¢å¸§å¤„ç†
    } else {
      setShowText('äººè„¸éœ€åœ¨è™šçº¿æ¡†å†…');
      return;
    }
  }

  const [photo, setPhoto] = useState<PhotoFile | null>(null);
  const photoRef = useRef<PhotoFile | null>(null);
  const takePicture = async () => {
    console.log(222);
    if (photoRef.current) return;
    if (camera.current) {
      try {
        setActivityLoading(true);
        const p = await camera.current.takePhoto();
        console.log('ğŸ ~ ç…§ç‰‡ ~ photo:', p);
        photoRef.current = p;
        const formData = new FormData();
        formData.append('projectId', myProject?.snowFlakeId || '');
        formData.append('face', {
          uri: Platform.OS === 'ios' ? p.path : `file://${p.path}`,
          name: 'face.jpg',
          type: 'image/jpeg',
        } as any);

        try {
          const response = await api.post(
            '/wechat/common/getUserByFace',
            formData,
            {
              headers: {
                'Content-Type': 'multipart/form-data',
              },
            },
          );

          console.log('âœ… ~ takePicture ~ response:', response);
          Alert.alert('æç¤º', 'å¯ä»¥è·³è½¬æ–°é¡µé¢', [
            {
              text: 'ç¡®å®š',
              onPress: () => {
                photoRef.current = null; // æ¸…ç©ºï¼Œå…è®¸å†æ¬¡æ‹ç…§
                startFrameProcessing();
              },
            },
          ]);
        } catch (error) {
          console.log('âŒ ~ takePicture ~ error:', error);
          // @ts-ignore
          Alert.alert('æç¤º', error.message, [
            {
              text: 'ç¡®å®š',
              onPress: () => {
                console.log(333);
                photoRef.current = null; // æ¸…ç©ºï¼Œå…è®¸å†æ¬¡æ‹ç…§
                startFrameProcessing();
              },
            },
          ]);
        }
      } catch (error) {
        console.error('âŒ ~ takePicture ~ error:', error);
      } finally {
        setActivityLoading(false);
      }
    }
  };

  function handleSkiaActions(faces: Face[], frame: DrawableFrame): void {
    'worklet';
    // if no faces are detected we do nothing
    // console.log('handleSkiaActions', 444);
    // if (!processingRef.current) return; // åœæ­¢å¤„ç†
    // console.log('handleSkiaActions', 555);

    if (faces.length <= 0) return;

    // console.log('SKIA - faces', faces.length, 'frame', frame.toString());

    const {bounds, contours, landmarks} = faces[0];

    // draw a blur shape around the face points
    const blurRadius = 25;
    const blurFilter = Skia.ImageFilter.MakeBlur(
      blurRadius,
      blurRadius,
      TileMode.Repeat,
      null,
    );
    const blurPaint = Skia.Paint();
    blurPaint.setImageFilter(blurFilter);
    const contourPath = Skia.Path.Make();
    const necessaryContours: (keyof Contours)[] = [
      'FACE',
      'LEFT_CHEEK',
      'RIGHT_CHEEK',
    ];

    necessaryContours.map(key => {
      contours?.[key]?.map((point, index) => {
        if (index === 0) {
          // it's a starting point
          contourPath.moveTo(point.x, point.y);
        } else {
          // it's a continuation
          contourPath.lineTo(point.x, point.y);
        }
      });
      contourPath.close();
    });

    frame.save();
    frame.clipPath(contourPath, ClipOp.Intersect, true);
    frame.render(blurPaint);
    frame.restore();

    // draw mouth shape
    const mouthPath = Skia.Path.Make();
    const mouthPaint = Skia.Paint();
    mouthPaint.setColor(Skia.Color('red'));
    const necessaryLandmarks: (keyof Landmarks)[] = [
      'MOUTH_BOTTOM',
      'MOUTH_LEFT',
      'MOUTH_RIGHT',
    ];

    necessaryLandmarks.map((key, index) => {
      const point = landmarks?.[key];
      if (!point) return;

      if (index === 0) {
        // it's a starting point
        mouthPath.moveTo(point.x, point.y);
      } else {
        // it's a continuation
        mouthPath.lineTo(point.x, point.y);
      }
    });
    mouthPath.close();
    frame.drawPath(mouthPath, mouthPaint);

    // draw a rectangle around the face
    const rectPaint = Skia.Paint();
    rectPaint.setColor(Skia.Color('blue'));
    rectPaint.setStyle(1);
    rectPaint.setStrokeWidth(5);
    frame.drawRect(bounds, rectPaint);
  }

  // å±…ä¸­çš„è™šçº¿æ¡†åæ ‡
  const boxLeft = (width - BOX_WIDTH) / 2;
  const boxTop = (height - BOX_HEIGHT) / 2;
  const boxRight = boxLeft + BOX_WIDTH;
  const boxBottom = boxTop + BOX_HEIGHT;
  return (
    <SafeAreaView style={styles.container}>
      <View
        style={[
          StyleSheet.absoluteFill,
          {
            alignItems: 'center',
            justifyContent: 'center',
          },
        ]}>
        <>
          <Camera
            photo={true}
            ref={camera}
            style={StyleSheet.absoluteFill}
            isActive={isActive}
            // @ts-ignore
            device={cameraDevice}
            onError={handleCameraMountError}
            onUIRotationChanged={handleUiRotation}
            // @ts-ignore

            faceDetectionOptions={{
              ...faceDetectionOptions,
              autoMode,
              cameraFacing,
            }}
            faceDetectionCallback={handleFacesDetected}
            skiaActions={handleSkiaActions}
          />
          {/* ä¸­é—´è™šçº¿æ¡† */}
          <View
            style={{
              position: 'absolute',
              left: boxLeft,
              top: boxTop,
              width: BOX_WIDTH,
              height: BOX_HEIGHT,
              borderWidth: 2,
              borderColor: 'white',
              borderStyle: 'dashed',
            }}
          />

          <TouchableOpacity
            style={styles.fab}
            onPress={async () => {
              setCameraFacing(current =>
                current === 'front' ? 'back' : 'front',
              );
            }}>
            <Text style={styles.fabText}>åˆ‡æ¢é•œå¤´</Text>
          </TouchableOpacity>

          <Animated.View style={boundingBoxStyle} />
        </>
      </View>

      <View
        style={{
          position: 'absolute',
          bottom: 50,
          left: 0,
          right: 0,
          display: 'flex',
          flexDirection: 'column',
        }}>
        <Text
          style={{
            fontSize: 22,
            width: '100%',
            textAlign: 'center',
            color: 'white',
          }}>
          {showText}
        </Text>
        <LoadingOverlay visible={activityLoading} title={title} />
      </View>
    </SafeAreaView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#000',
  },
  fab: {
    position: 'absolute',
    top: 0,
    left: 0,
    width: 100,
    height: 50,
    backgroundColor: '#2080F0',
    justifyContent: 'center',
    alignItems: 'center',
  },

  fabText: {
    color: '#fff',
    fontSize: 20,
    fontWeight: 'bold',
  },
});
